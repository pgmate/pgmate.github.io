<!doctype html>
<html lang="en" dir="ltr" class="docs-wrapper plugin-docs plugin-id-default docs-version-current docs-doc-page docs-doc-id-copilot" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.7.0">
<title data-rh="true">ü§ñ Copilot | PGMate</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:image" content="https://pgmate.github.io/img/pgmate-social-card.png"><meta data-rh="true" name="twitter:image" content="https://pgmate.github.io/img/pgmate-social-card.png"><meta data-rh="true" property="og:url" content="https://pgmate.github.io/docs/copilot"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docusaurus_version" content="current"><meta data-rh="true" name="docusaurus_tag" content="docs-default-current"><meta data-rh="true" name="docsearch:version" content="current"><meta data-rh="true" name="docsearch:docusaurus_tag" content="docs-default-current"><meta data-rh="true" property="og:title" content="ü§ñ Copilot | PGMate"><meta data-rh="true" name="description" content="Copilot is an EXPERIMENTAL TEXT2SQL interface that uses Generative AI to convert human input into SQL code that you can execute inline with the conversation."><meta data-rh="true" property="og:description" content="Copilot is an EXPERIMENTAL TEXT2SQL interface that uses Generative AI to convert human input into SQL code that you can execute inline with the conversation."><link data-rh="true" rel="icon" href="/img/favicon/pgmate.ico"><link data-rh="true" rel="canonical" href="https://pgmate.github.io/docs/copilot"><link data-rh="true" rel="alternate" href="https://pgmate.github.io/docs/copilot" hreflang="en"><link data-rh="true" rel="alternate" href="https://pgmate.github.io/docs/copilot" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="PGMate RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="PGMate Atom Feed">
<link rel="alternate" type="application/json" href="/blog/feed.json" title="PGMate JSON Feed"><link rel="stylesheet" href="/assets/css/styles.f790b48c.css">
<script src="/assets/js/runtime~main.73469040.js" defer="defer"></script>
<script src="/assets/js/main.c695d3e9.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return window.localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"light")}(),function(){try{const n=new URLSearchParams(window.location.search).entries();for(var[t,e]of n)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_fXgn" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/pgmate-logo.png" alt="PGMate" class="themedComponent_mlkZ themedComponent--light_NVdE"><img src="/img/pgmate-logo.png" alt="PGMate" class="themedComponent_mlkZ themedComponent--dark_xIcU"></div><b class="navbar__title text--truncate">PGMate</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Docs</a><a class="navbar__item navbar__link" href="/blog">Blog</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/pgmate/pgmate.github.io" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a><div class="toggle_vylO colorModeToggle_DEke"><button class="clean-btn toggleButton_gllP toggleButtonDisabled_aARS" type="button" disabled="" title="Switch between dark and light mode (currently light mode)" aria-label="Switch between dark and light mode (currently light mode)" aria-live="polite" aria-pressed="false"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_pyhR"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_wfgR"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_Bca1"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_z2l0"><div class="docsWrapper_hBAB"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_sjWU" type="button"></button><div class="docRoot_UBD9"><aside class="theme-doc-sidebar-container docSidebarContainer_YfHR"><div class="sidebarViewport_aRkj"><div class="sidebar_njMd"><nav aria-label="Docs sidebar" class="menu thin-scrollbar menu_SIkG"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">üê≥ Docker QuickStart</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/connections-manager">üë©‚Äçüíª Connections Manager</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" href="/docs/copilot">ü§ñ Copilot</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/keyboard-shortcuts">‚å®Ô∏è Keyboard Shortcuts</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/sql-studio">‚å®Ô∏è SQL Studio</a></li></ul></nav></div></div></aside><main class="docMainContainer_TBSr"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_VOVn"><div class="docItemContainer_Djhp"><article><nav class="theme-doc-breadcrumbs breadcrumbsContainer_Z_bl" aria-label="Breadcrumbs"><ul class="breadcrumbs" itemscope="" itemtype="https://schema.org/BreadcrumbList"><li class="breadcrumbs__item"><a aria-label="Home page" class="breadcrumbs__link" href="/"><svg viewBox="0 0 24 24" class="breadcrumbHomeIcon_YNFT"><path d="M10 19v-5h4v5c0 .55.45 1 1 1h3c.55 0 1-.45 1-1v-7h1.7c.46 0 .68-.57.33-.87L12.67 3.6c-.38-.34-.96-.34-1.34 0l-8.36 7.53c-.34.3-.13.87.33.87H5v7c0 .55.45 1 1 1h3c.55 0 1-.45 1-1z" fill="currentColor"></path></svg></a></li><li itemscope="" itemprop="itemListElement" itemtype="https://schema.org/ListItem" class="breadcrumbs__item breadcrumbs__item--active"><span class="breadcrumbs__link" itemprop="name">ü§ñ Copilot</span><meta itemprop="position" content="1"></li></ul></nav><div class="tocCollapsible_ETCw theme-doc-toc-mobile tocMobile_ITEo"><button type="button" class="clean-btn tocCollapsibleButton_TO0P">On this page</button></div><div class="theme-doc-markdown markdown"><header><h1>ü§ñ Copilot</h1></header>
<p>Copilot is an <strong>EXPERIMENTAL TEXT2SQL</strong> interface that uses <em>Generative AI</em> to convert human input into SQL code that you can execute inline with the conversation.</p>
<div style="position:relative;padding-bottom:56.25%;height:0;overflow:hidden;margin-bottom:1rem"><iframe src="https://www.youtube.com/embed/hAvWcbox7BE" title="PGMate Copilot Demo" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" style="position:absolute;top:0;left:0;width:100%;height:100%"></iframe></div>
<p>If you use ChatGPT or similar chat-based interfaces, you already know how to use it. Actually, if you ever used any Messenger or WhatsAPP you do. Just imagine you have a great guy on the other side, that is not only a Postgres and SQL pro, but <strong>also knows what your database is about and <em>what&#x27;s inside it</em></strong>.</p>
<p>Well, it <em>PARTIALLY KNOWS WHAT&#x27;S INSIDE</em>.<br>
<!-- -->Right now, Copilot know about your database structure: schemas, tables, fields, constraints and indexes.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="data-privacy-first">Data Privacy First<a href="#data-privacy-first" class="hash-link" aria-label="Direct link to Data Privacy First" title="Direct link to Data Privacy First">‚Äã</a></h2>
<p>üëâ It <strong>DOESN&#x27;T KNOW ABOUT YOUR DATA!!!</strong></p>
<p>And this is both a pro and a cons:</p>
<p>On one side, your privacy is guaranteed (check the source code! It&#x27;s all open for you to read) and you can safely run Copilot on a production database knowing that your data - or your customers&#x27; data - is not sent to the LLM.</p>
<p>On the other side, not knowing the data is a limitation to Copilot&#x27;s ability in crafting performant queries. After all, <strong>knowing the data is the core foundation of database optimization!</strong></p>
<p>üî• I have in mind to let Copilot take samples of the data in the future, but that will be a <strong>strictly opt-in</strong> feature that you will have to enable via environmental variable.</p>
<blockquote>
<p>No data will EVER be sent around without your explicit request/consent.</p>
</blockquote>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="current-engine">Current Engine<a href="#current-engine" class="hash-link" aria-label="Direct link to Current Engine" title="Direct link to Current Engine">‚Äã</a></h2>
<p>PGMate&#x27;s Copilot runs on OpenAI APIs.</p>
<blockquote>
<p>This means that you can quickly switch to any provider that is compatible with it, like DeepSeek or Qwen.</p>
</blockquote>
<div class="language-bash codeBlockContainer_Ckt0 theme-code-block" style="--prism-color:#393A34;--prism-background-color:#f6f8fa"><div class="codeBlockContent_biex"><pre tabindex="0" class="prism-code language-bash codeBlock_bY9V thin-scrollbar" style="color:#393A34;background-color:#f6f8fa"><code class="codeBlockLines_e6Vv"><span class="token-line" style="color:#393A34"><span class="token plain">docker run ... \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -e PGMATE_OPENAPI_KEY=xxx \</span><br></span><span class="token-line" style="color:#393A34"><span class="token plain">  -e PGMATE_OPENAPI_URL=https://other-api.ai</span><br></span></code></pre><div class="buttonGroup__atx"><button type="button" aria-label="Copy code to clipboard" title="Copy" class="clean-btn"><span class="copyButtonIcons_eSgA" aria-hidden="true"><svg viewBox="0 0 24 24" class="copyButtonIcon_y97N"><path fill="currentColor" d="M19,21H8V7H19M19,5H8A2,2 0 0,0 6,7V21A2,2 0 0,0 8,23H19A2,2 0 0,0 21,21V7A2,2 0 0,0 19,5M16,1H4A2,2 0 0,0 2,3V17H4V3H16V1Z"></path></svg><svg viewBox="0 0 24 24" class="copyButtonSuccessIcon_LjdS"><path fill="currentColor" d="M21,7L9,19L3.5,13.5L4.91,12.09L9,16.17L19.59,5.59L21,7Z"></path></svg></span></button></div></div></div>
<p>üöß Copilot still uses <code>gpt-4o</code> and <code>gpt-4o-mini</code> as models names, but we will soon expose and ENV configuration to map the model to a <code>strong</code> and <code>fast</code> abstration in the name.</p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="current-capabilities">Current Capabilities<a href="#current-capabilities" class="hash-link" aria-label="Direct link to Current Capabilities" title="Direct link to Current Capabilities">‚Äã</a></h2>
<p>I&#x27;ve run pair programming sessions in which I managed to build, seed, and query a failrily complex schema aimed to support a <a href="https://www.imdb.com/title/tt0332379/" target="_blank" rel="noopener noreferrer">School of Rock</a> scenario.<br>
<!-- -->For less than $0.03.<br>
<!-- -->üòé</p>
<p>Copilot defaults to a fast model (<code>gpt-4o-mini</code>) and a compact context (table and fields names) for cost optimization. You can switch to a stronger model (<code>gpt-4o</code>) and a full context (adds field types, constraints, indexes) for complex requests using the UI&#x27;s toggles:</p>
<p><img decoding="async" loading="lazy" alt="Copilot options - PGMate" src="/assets/images/pgmate-copilot-options-09a91522396c0397a205eaf49b738490.png" width="1920" height="1024" class="img_ev3q"></p>
<h2 class="anchor anchorWithStickyNavbar_LWe7" id="development-plans">Development Plans<a href="#development-plans" class="hash-link" aria-label="Direct link to Development Plans" title="Direct link to Development Plans">‚Äã</a></h2>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="llm-abstraction">LLM Abstraction<a href="#llm-abstraction" class="hash-link" aria-label="Direct link to LLM Abstraction" title="Direct link to LLM Abstraction">‚Äã</a></h3>
<p>I don&#x27;t believe in abstractions such as ORMs and alikes. It is my opinion and experience that mastering your tool of choiche yields the best results. That&#x27;s why I use Postgres by the way...</p>
<p>Even in the world of LLM this stands true.</p>
<p>The way a prompt needs to be phrased is influenced by the model that will consume it. For different models focuses on different aspects.</p>
<p>Nevertheless, we are still in the early days of GenAI and being flexible is important.</p>
<p>PGMate will be model-agnostic AND model-specific with this approach:</p>
<ol>
<li>You will be able to use any provider that is compatible with OpenAI APIs structure through ENV VARS.<!-- -->
<small><p>(looks like the world of LLMs have accepted it as a de-facto standard)</p></small>
</li>
<li>You will be able to associate any model to a map of names (Eg. <code>strong</code> and <code>fast</code>)</li>
<li>You will be able to customize the prompts by writing particular prompt-files and mapping a volume</li>
</ol>
<p>This approach should yield the best combination of flexibility and customization.</p>
<p>I hope the communitiy will join on and help building a library of prompts so that PGMate will be able to switch to the most appropriate prompt based on the model selected by the user.</p>
<p>I envision this to be the best possible outcome, so the user only have to provide an API KEY to any of the supported providers.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="improve-context-structure">Improve Context Structure<a href="#improve-context-structure" class="hash-link" aria-label="Direct link to Improve Context Structure" title="Direct link to Improve Context Structure">‚Äã</a></h3>
<p>Right now the context that PGMate provides is list-based (list of <code>{schema}.{table}</code> with a list of fields inside). But I&#x27;ve recently found out that hierarchical structures are better for LLMs.</p>
<p>This seems to be a low-hanging fruit in improving Copilot&#x27;s performances, so I will definitely work on it soon. You can also join in and edit the mapping functions ‚ù§Ô∏è.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="layered-approach">Layered Approach<a href="#layered-approach" class="hash-link" aria-label="Direct link to Layered Approach" title="Direct link to Layered Approach">‚Äã</a></h3>
<p>Another approach to improve the LLMs performance is to introduce a two-step approach:</p>
<ol>
<li>Ask the model to <strong>reduce a broad but shallow context</strong> into a list of objects needed to solve the problem</li>
<li>Ask the model to <strong>solve the problem using a narrow but deep context</strong> crafted out of the first step&#x27;s selection</li>
</ol>
<p>This should balance token consumption and completeness of the information that are passed to the model.</p>
<p>I&#x27;m also studying hard on tokens prioritization and I have in mind to craft a ranking algorithm that is partially euristic-based and LLM-based, so that the context is sorted by ranking in the scope of the problem that the user is presenting.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="context-vectorization">Context Vectorization<a href="#context-vectorization" class="hash-link" aria-label="Direct link to Context Vectorization" title="Direct link to Context Vectorization">‚Äã</a></h3>
<p>The idea is to craft a deep context out of any object, hash it and vectorize it in the default database for any given connection. Such vector db would be kept in sync by a background process that watches schema-changes on an active connection, and updates the vectors of the portions of the schema that have changed.</p>
<p>The layered approach that we describle could either replace the first step with a local vector based search (basically we would go RAG), or introduce a first step in which the broad by shallow context is pre-filtered by RAG.</p>
<p>Although I&#x27;m positive this will help with cost management (embeddings are much cheaper than tokens), I&#x27;m not sure this will work well. We will have to try.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="manual-context-settings">Manual Context Settings<a href="#manual-context-settings" class="hash-link" aria-label="Direct link to Manual Context Settings" title="Direct link to Manual Context Settings">‚Äã</a></h3>
<p>The idea is to add a settings panel with a schema tree (<code>schema / table / [fields | constraints | indexes]</code>) and let the user check/uncheck the objects that need to be passed down to the LLM.</p>
<p>üëâ A simple toggle could help switching from manual to automated mode pretty much like your car does.</p>
<p>This approach requires enough human-knowledge to know which parts of the schema are relevant for the next request, offsetting the task of writing the code to the LLM.</p>
<p>I believe this is a high performing approach.</p>
<p>ü§∑‚Äç‚ôÇÔ∏è I also love the &quot;human in the loop&quot; concept, for I wish with all my heart NOT TO BE REPLACED by the AI.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="data-spaces">Data Spaces<a href="#data-spaces" class="hash-link" aria-label="Direct link to Data Spaces" title="Direct link to Data Spaces">‚Äã</a></h3>
<p>This is not my idea. It&#x27;s Uber&#x27;s.</p>
<p>In the linked paper they simply introduce a &quot;step zero&quot; in the layered approach and manually craft multiple manual contexts that are stored in a vectorized table.</p>
<p>Each space (well, it&#x27;s just a selection of <code>schema / table / [fields | constraints | indexes]</code>) would have a name and a description. The description is vectorized so that the first step in the &quot;layered approach&quot; described above would be to use a fast LLM to match the most appropriate space by intention.</p>
<p>How well this matching would work depends on how well the space&#x27;s description is matched by the user&#x27;s request at chat-time.</p>
<p>Also in this case, I love the idea of introducing the spaces AND letting the user manually choose which space to use during a chat interaction.</p>
<p>Again, I really wish I will still be relevant 5 years down the line ü§£.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="chat-history-summarization">Chat History Summarization<a href="#chat-history-summarization" class="hash-link" aria-label="Direct link to Chat History Summarization" title="Direct link to Chat History Summarization">‚Äã</a></h3>
<p>I&#x27;m a rather poor guy. I&#x27;ve born in a humble hard-working family, and money have always been a scarce resource. So most of my work and my efforts go in the direction of cost optimization üòá.</p>
<p>I have 3 ideas how to keep tokens consumption down to a capped linear growth:</p>
<p>The <strong>dumb idea</strong> is to truncate the chat history. That&#x27;s what Copilot does today, and what many simple tools out there do as well. Today the default truncation is at 10 messages, and I&#x27;ve found it works great because the model is constanly fed with fresh info about the schema, so it doesn&#x27;t need to remember a table that was created 15 messages ago. It knows it anyway.</p>
<p>But this is still a bit dumb as an approach. We may end up finding out that DUMB IS BEST, but I would like to give it a go with two less dumb approaches.</p>
<p>The classic summary message. This consist in asking an independent model to keep summarizing old messages, feeding the LLM with:</p>
<ul>
<li>old summarized History</li>
<li>X fresh messages (5-&gt;10)</li>
<li>the new user request</li>
<li>the schema context</li>
</ul>
<p>This approach consumes tokens to keep refining the summary, and it introduces some challenges in keeping a relevant-first list into the summary so to kick out less-relevant information once the summary reaches a max-size.</p>
<p>As far as I understand, this is what tools like ChatGPT do under the hood.</p>
<p>Another approach that I&#x27;d like to try is simply to ask a sidekick LLM to minify the last user request by removing all the human level language that don&#x27;t provide meaning to the llm.</p>
<p>A request like <code>PLEASE GIVE ME THE NEW USERS</code> would at the very least remove the word <code>PLEASE</code> from the chat history.</p>
<p>This way, PGMate would maintain a parallel chat with the &quot;compressed messages&quot;. And this invisible history could be capped (the dump approach) or summarized (as describle before) as well.</p>
<p>All of this will require time to implement and KPIs to assess how good the approach is!</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="data-sampling">Data Sampling<a href="#data-sampling" class="hash-link" aria-label="Direct link to Data Sampling" title="Direct link to Data Sampling">‚Äã</a></h3>
<p>This is an extremely delicate subject because sending your own data into the unknown is scary, and it could be illegal as well üëÆ.</p>
<p>On the other hands, it is well known that the only real approach to data optimization is:<br>
<strong>üëâ KNOW YOUR DATA üëà</strong>.</p>
<p>Allowing PGMate to grap SOME data from the refined context, and sending those data into the LLM could improve the results. Especially when combined with indexes information.</p>
<p>I made some empirical tests using plain ChatGPT and manually crafted contexts, and the model yields different queries with different plans. So I believe this could be relevant for improving the quality of the resulting code.</p>
<p>This feature must be implemented as STRICTLY OPT-IN so there could be no scenario in which a PGMate user says &quot;I didn&#x27;t know my data was exposed&quot;. That would not be acceptable.</p>
<p>As last consideration, I don&#x27;t think it would be an issue to share with the model development datasets or anonymized production ones.</p>
<p>I envision an anonymized data sampler that can apply fixed rules for scrambling the data that are sent into the LLM.</p>
<h3 class="anchor anchorWithStickyNavbar_LWe7" id="extended-statistics">Extended Statistics<a href="#extended-statistics" class="hash-link" aria-label="Direct link to Extended Statistics" title="Direct link to Extended Statistics">‚Äã</a></h3>
<p>The current version of Copilot already taps into Postgres default statistics to send in the estimated rows into the LLM.</p>
<p>This should be extended with unique values, the instogram etc... As well as info from <code>pg_stats</code> when enabled.</p>
<p>Gathering the information is rather easy, figuring out how much of this information needs to be provided - hence balancing the cost-to-performance - is another thing.</p>
<p>I don&#x27;t have ideas about it.<br>
<!-- -->Yet.</p></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="row margin-top--sm theme-doc-footer-edit-meta-row"><div class="col"><a href="https://github.com/pgmate/pgmate.github.io/tree/main/docs/copilot.mdx" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_Z9Sw" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_JAkA"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages"><a class="pagination-nav__link pagination-nav__link--prev" href="/docs/connections-manager"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">üë©‚Äçüíª Connections Manager</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/docs/keyboard-shortcuts"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">‚å®Ô∏è Keyboard Shortcuts</div></a></nav></div></div><div class="col col--3"><div class="tableOfContents_bqdL thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#data-privacy-first" class="table-of-contents__link toc-highlight">Data Privacy First</a></li><li><a href="#current-engine" class="table-of-contents__link toc-highlight">Current Engine</a></li><li><a href="#current-capabilities" class="table-of-contents__link toc-highlight">Current Capabilities</a></li><li><a href="#development-plans" class="table-of-contents__link toc-highlight">Development Plans</a><ul><li><a href="#llm-abstraction" class="table-of-contents__link toc-highlight">LLM Abstraction</a></li><li><a href="#improve-context-structure" class="table-of-contents__link toc-highlight">Improve Context Structure</a></li><li><a href="#layered-approach" class="table-of-contents__link toc-highlight">Layered Approach</a></li><li><a href="#context-vectorization" class="table-of-contents__link toc-highlight">Context Vectorization</a></li><li><a href="#manual-context-settings" class="table-of-contents__link toc-highlight">Manual Context Settings</a></li><li><a href="#data-spaces" class="table-of-contents__link toc-highlight">Data Spaces</a></li><li><a href="#chat-history-summarization" class="table-of-contents__link toc-highlight">Chat History Summarization</a></li><li><a href="#data-sampling" class="table-of-contents__link toc-highlight">Data Sampling</a></li><li><a href="#extended-statistics" class="table-of-contents__link toc-highlight">Extended Statistics</a></li></ul></li></ul></div></div></div></div></main></div></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Contents</div><ul class="footer__items clean-list"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Docs</a></li><li class="footer__item"><a class="footer__link-item" href="/blog">Blog</a></li></ul></div><div class="col footer__col"><div class="footer__title">Contribute</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://github.com/pgmate/pgmate" target="_blank" rel="noopener noreferrer" class="footer__link-item">Contribute to PGMate Client<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/pgmate/contents" target="_blank" rel="noopener noreferrer" class="footer__link-item">Add content to PGMate<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/pgmate/pgmate.github.io" target="_blank" rel="noopener noreferrer" class="footer__link-item">Edit this website<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items clean-list"><li class="footer__item"><a href="https://gitpod.io/#https://github.com/pgmate/demo" target="_blank" rel="noopener noreferrer" class="footer__link-item">Try it online! (no credentials, no credit card)<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li><li class="footer__item"><a href="https://github.com/pgmate/pgmate" target="_blank" rel="noopener noreferrer" class="footer__link-item">Star on GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_nPIU"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright ¬© 2025 PGMate, Inc. Built with Docusaurus.</div></div></div></footer></div>
</body>
</html>